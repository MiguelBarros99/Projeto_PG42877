DNNFull
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Train basic models: 

run_dnn_simple
{'self': <propythia.deep_ml.DeepML object at 0x000001CEA1C88100>, 'input_dim': 361, 'optimizer': 'Adam', 'hidden_layers': (256, 256, 128, 128), 'dropout_rate': (0.1, 0.1, 0.1, 0.1), 'batchnormalization': (True,), 'l1': 1e-05, 'l2': 0.0001, 'final_dropout_value': 0.3, 'initial_dropout_value': 0.0, 'loss_fun': 'sparse_categorical_crossentropy', 'activation_fun': 'softmax', 'cv': None, 'optType': None, 'param_grid': None, 'n_iter_search': 15, 'n_jobs': 1, 'scoring': make_scorer(matthews_corrcoef), 'func_name': 'run_dnn_simple'}
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x000001CEA1B9BCD0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x000001CEA1B9BBB0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x000001CEA1B9B910>]
===TRAIN MODELS===

run_model
('Training Accuracy mean: ', 0.9018531639254495)
('Validation Accuracy mean: ', 0.7681402527214436)
('Training Loss mean: ', 0.48163632462533673)
('Validation Loss mean: ', 1.1006302123659113)
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense (Dense)                (None, 256)               92672     
_________________________________________________________________
batch_normalization (BatchNo (None, 256)               1024      
_________________________________________________________________
dropout (Dropout)            (None, 256)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 256)               65792     
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
dropout_1 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 128)               32896     
_________________________________________________________________
batch_normalization_2 (Batch (None, 128)               512       
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 128)               16512     
_________________________________________________________________
batch_normalization_3 (Batch (None, 128)               512       
_________________________________________________________________
dropout_3 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 7)                 903       
=================================================================
Total params: 211,847
Trainable params: 210,311
Non-trainable params: 1,536
_________________________________________________________________Finished run_model in 75.7495 secs


===simple evaluate===

model_simple_evaluate


('test loss, test acc:', [1.2027614116668701, 0.7897507548332214])
===SCORING TEST SET ===

model_complete_evaluate
{'self': <propythia.deep_ml.DeepML object at 0x000001CEA1C88100>, 'x_test': None, 'y_test': None, 'model': None}
report

              precision    recall  f1-score   support

           0       0.82      0.81      0.82      1785
           1       0.76      0.82      0.79      2987
           2       0.80      0.83      0.82      3220
           3       0.83      0.71      0.76       626
           4       0.82      0.54      0.65       347
           5       0.64      0.46      0.54       266
           6       0.67      0.44      0.53        77

    accuracy                           0.79      9308
   macro avg       0.76      0.66      0.70      9308
weighted avg       0.79      0.79      0.79      9308


===confusion_matrix===

[[1442  168  132   20    6   11    6]
 [ 123 2448  348   31   14   17    6]
 [  92  378 2675   30   17   25    3]
 [  33   68   69  444    1   10    1]
 [  28   63   54   11  186    4    1]
 [  24   72   44    2    2  122    0]
 [   9   21   12    0    0    1   34]]

===multilabel confusion matrix===

[[[7214  309]
  [ 343 1442]]

 [[5551  770]
  [ 539 2448]]

 [[5429  659]
  [ 545 2675]]

 [[8588   94]
  [ 182  444]]

 [[8921   40]
  [ 161  186]]

 [[8974   68]
  [ 144  122]]

 [[9214   17]
  [  43   34]]]

===scores report===
metrics	scores
Accuracy	0.7898
MCC	0.7101
log_loss	1.0055
f1 score weighted	0.7872
f1 score macro	0.6999
f1 score micro	0.7898
roc_auc ovr	0.9425
roc_auc ovo	0.9360
precision	0.7897
recall	0.7898
