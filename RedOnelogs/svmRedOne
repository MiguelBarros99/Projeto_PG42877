svmRedOne
===TRAIN MODELS===

train_best_model
{'self': <propythia.shallow_ml.ShallowML object at 0x00000283AED01820>, 'model_name': 'svm', 'model': None, 'scaler': None, 'score': make_scorer(matthews_corrcoef), 'cv': 5, 'optType': 'gridSearch', 'param_grid': {'clf__C': [32.0], 'clf__kernel': ['rbf']}, 'n_jobs': 5, 'random_state': 1, 'n_iter': 15, 'refit': True, 'params': {'probability': True}, 'start': 767.3664423}
['Model with rank: 1\n', 'Mean validation score: 0.322 (std: 0.025)\n', "Parameters: {'clf__C': 32.0, 'clf__kernel': 'rbf'}\n", '\n']
Best score (scorer: make_scorer(matthews_corrcoef)) and parameters from a 5-fold cross validation:

MCC score:	0.322

Parameters:	{'clf__C': 32.0, 'clf__kernel': 'rbf'}

Finished train_best_model in 754.9176 secs

	means	stds	clf__C	clf__kernel
0	0.322	0.025	32.000	rbf

===SCORING TEST SET ===

score_testset
{'self': <propythia.shallow_ml.ShallowML object at 0x00000283AED01820>, 'classifier': Pipeline(steps=[('scl', None),
                ('clf', SVC(C=32.0, probability=True, random_state=1))])}
report

              precision    recall  f1-score   support

           0       0.48      0.52      0.50       431
           1       0.50      0.60      0.54       727
           2       0.53      0.55      0.54       709
           3       0.53      0.32      0.40       187
           4       0.52      0.28      0.37       135
           5       0.28      0.16      0.20       106
           6       0.50      0.12      0.19        25

    accuracy                           0.50      2320
   macro avg       0.48      0.36      0.39      2320
weighted avg       0.50      0.50      0.49      2320


confusion_matrix

[[224  99  79  11   6  12   0]
 [ 77 434 164  16  15  19   2]
 [ 95 196 392  17   3   5   1]
 [ 23  57  33  59   9   6   0]
 [ 21  27  42   7  38   0   0]
 [ 16  50  20   1   2  17   0]
 [  7   9   5   0   0   1   3]]

multilabel confusion matrix

None

scores report
metrics	scores
Accuracy	0.5030
MCC	0.3313
log_loss	1.2981
f1 score weighted	0.4937
f1 score macro	0.3924
f1 score micro	0.5030
roc_auc ovr	0.7661
roc_auc ovo	0.7718
precision	0.5003
recall	0.5030
svmRedOnesvmRedOne
===TRAIN MODELS===

train_best_model
{'self': <propythia.shallow_ml.ShallowML object at 0x0000025012D81790>, 'model_name': 'svm', 'model': None, 'scaler': None, 'score': make_scorer(matthews_corrcoef), 'cv': 5, 'optType': 'gridSearch', 'param_grid': {'clf__C': [32.0], 'clf__kernel': ['rbf']}, 'n_jobs': 5, 'random_state': 1, 'n_iter': 15, 'refit': True, 'params': {'probability': True}, 'start': 185.3705935}
['Model with rank: 1\n', 'Mean validation score: 0.322 (std: 0.025)\n', "Parameters: {'clf__C': 32.0, 'clf__kernel': 'rbf'}\n", '\n']
Best score (scorer: make_scorer(matthews_corrcoef)) and parameters from a 5-fold cross validation:

MCC score:	0.322

Parameters:	{'clf__C': 32.0, 'clf__kernel': 'rbf'}

Finished train_best_model in 517.0423 secs

	means	stds	clf__C	clf__kernel
0	0.322	0.025	32.000	rbf

===SCORING TEST SET ===

score_testset
{'self': <propythia.shallow_ml.ShallowML object at 0x0000025012D81790>, 'classifier': Pipeline(steps=[('scl', None),
                ('clf', SVC(C=32.0, probability=True, random_state=1))])}
report

              precision    recall  f1-score   support

           0       0.48      0.52      0.50       431
           1       0.50      0.60      0.54       727
           2       0.53      0.55      0.54       709
           3       0.53      0.32      0.40       187
           4       0.52      0.28      0.37       135
           5       0.28      0.16      0.20       106
           6       0.50      0.12      0.19        25

    accuracy                           0.50      2320
   macro avg       0.48      0.36      0.39      2320
weighted avg       0.50      0.50      0.49      2320


confusion_matrix

[[224  99  79  11   6  12   0]
 [ 77 434 164  16  15  19   2]
 [ 95 196 392  17   3   5   1]
 [ 23  57  33  59   9   6   0]
 [ 21  27  42   7  38   0   0]
 [ 16  50  20   1   2  17   0]
 [  7   9   5   0   0   1   3]]

multilabel confusion matrix

None

scores report
metrics	scores
Accuracy	0.5030
MCC	0.3313
log_loss	1.2981
f1 score weighted	0.4937
f1 score macro	0.3924
f1 score micro	0.5030
roc_auc ovr	0.7661
roc_auc ovo	0.7718
precision	0.5003
recall	0.5030
